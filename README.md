# Automated Blog Pipeline for Technical Leadership

A fully automated GitHub Actions pipeline that transforms rough drafts into polished blog posts while preserving your authentic voice and unique insights.

## Overview

This pipeline implements a 5-stage writing process that **adapts to your content type**:

1. **Intake & Structure** - Detects content type, extracts core insight, identifies elements to preserve
2. **Grounding & Research** - Finds supporting evidence (or recognizes when your experience IS the evidence)
3. **Expansion** - Writes full draft using inverted pyramid, adapting style to content type
4. **Style & Polish** - Refines while preserving author voice and personality
5. **Technical Review** - Quality check against the content's own goals

### Content Types Supported

| Type | Description | Grounding Strategy |
|------|-------------|-------------------|
| `personal_insight` | Personal experiences, lessons learned | Author's experience IS the evidence |
| `technical_howto` | Tutorials, implementation guides | External docs, code examples |
| `business_case` | ROI arguments, strategy pieces | Industry data, case studies |
| `thought_leadership` | Framework proposals, trend analysis | Mix of personal and external |

## How It Works

```
┌─────────────────────────────────────┐
│ 1. Write rough notes in drafts/    │
│    Example: drafts/my-idea.md       │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ 2. Push to GitHub                   │
│    git add drafts/my-idea.md        │
│    git commit -m "Draft post"       │
│    git push                          │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ 3. GitHub Actions automatically:    │
│    - Detects content type           │
│    - Preserves your unique voice    │
│    - Researches (when appropriate)  │
│    - Writes polished post           │
│    - Creates Pull Request           │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ 4. You review PR and merge          │
│    - Comment on specific lines      │
│    - Request changes if needed      │
│    - Merge when satisfied           │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ 5. Post auto-publishes to blog      │
│    (via GitHub Pages)                │
└─────────────────────────────────────┘
```

## Setup Instructions

### Prerequisites

- GitHub repository with Pages enabled
- Anthropic API key (Claude)
- Bing Search API key (optional - for external research)

### Step 1: Repository Structure

Organize your repo like this:

```
your-blog-repo/
├── .github/
│   └── workflows/
│       └── blog-pipeline.yml
├── pipeline/
│   ├── requirements.txt
│   ├── llm_client.py
│   ├── prompts.py
│   ├── stage1_structure.py
│   ├── stage2_grounding.py
│   ├── stage3_expansion.py
│   ├── stage4_polish.py
│   └── stage5_review.py
├── drafts/           # Your rough notes go here
├── posts/            # Published posts (generated by pipeline)
└── _posts/           # Or whatever your Jekyll/Hugo theme uses
```

### Step 2: Configure GitHub Secrets

Go to your repo → Settings → Secrets and variables → Actions

Add these secrets:

1. **ANTHROPIC_API_KEY**
   - Your Anthropic API key for Claude
   - Get it from: https://console.anthropic.com/

2. **BING_SEARCH_KEY** (optional)
   - Bing Search API key for web research
   - Without this, Stage 2 will skip web search
   - Note: For personal insight posts, external research is often not needed

### Alternative: Azure OpenAI

The pipeline also supports Azure OpenAI. Set these secrets instead:

| Secret | Description |
|--------|-------------|
| `AZURE_OPENAI_ENDPOINT` | `https://your-resource.openai.azure.com/` |
| `AZURE_OPENAI_KEY` | Your Azure OpenAI API key |
| `AZURE_OPENAI_DEPLOYMENT` | Your model deployment name |

The `llm_client.py` auto-detects which provider to use based on available environment variables.

### Step 3: Copy Pipeline Files

1. Copy all files from this repository to yours
2. Make scripts executable:
   ```bash
   chmod +x pipeline/*.py
   ```

### Step 4: Test the Pipeline

Create a test draft:

```bash
# Create drafts directory
mkdir -p drafts

# Write a test draft
cat > drafts/test-post.md << 'EOF'
# Test Post Idea

I've noticed that many engineering teams struggle with context loss when moving fast with AI coding tools. When you generate code at high velocity, the traditional communication patterns break down. 

Key observations:
- Documentation lags behind code generation
- Team members lose track of what was built and why
- Context becomes tribal knowledge
- New team members struggle to catch up

I think we need new communication paradigms. Maybe AI-readable status files that capture decisions, rationale, and system state in a format both humans and AI can consume efficiently.

This could bridge the context gap in AI-accelerated development.
EOF

# Commit and push
git add drafts/test-post.md
git commit -m "Test blog pipeline"
git push
```

### Step 5: Monitor the Action

1. Go to your repo → Actions tab
2. Watch the "Blog Pipeline" workflow run
3. After 2-3 minutes, check Pull Requests
4. Review the generated post

## Writing Drafts

### What to Include in Your Draft

Your rough notes should contain:
- Main idea or thesis
- Key observations or data points
- Examples you want to include
- Any specific sources you know about

**Example:**

```markdown
# Communication in the AI Age

Problem: AI tools like Cursor and Copilot generate code faster than we can document it.

Observation from my team:
- We shipped 3 features in 2 weeks using Amplifier
- Generated 15k lines of code
- But only 2 pages of docs
- New PM couldn't understand what we built

Solution idea: Create ".context" files that are:
- Machine readable
- Human scannable  
- Auto-updated by AI tools
- Version controlled

Similar to how .env files work but for context instead of config.

Need to research: What formats exist? How do other teams handle this?
```

### What NOT to Worry About

The pipeline handles:
- ✅ Research and finding sources
- ✅ Structuring with inverted pyramid
- ✅ Adding specific metrics and examples
- ✅ Proper citations
- ✅ Technical leadership tone
- ✅ Frontmatter and formatting

## Customization

### Adjust AI Temperature

Edit the `temperature` parameter in each stage script:
- Lower (0.1-0.3): More consistent, factual
- Higher (0.5-0.8): More creative, varied

### Change Research Focus

Edit `stage2_grounding.py`:
- Add more search queries
- Change source prioritization
- Adjust search filters

### Modify Output Format

Edit `stage5_review.py`:
- Change frontmatter template
- Adjust metadata fields
- Modify output location

### Add Custom Prompts

Each stage has a `PROMPT` variable at the top - customize as needed.

## Workflow Tips

### For Simple Posts
1. Write quick notes in `drafts/`
2. Push and let pipeline handle everything
3. Review PR, merge

### For Complex Posts
1. Start with detailed draft
2. Let pipeline create first version
3. Use PR comments to request specific changes
4. Can manually edit before merging

## PR Comment Revisions

After the pipeline creates a PR, you can request revisions by commenting directly on specific lines in the "Files Changed" tab. The AI will automatically process your feedback and commit changes.

### How It Works

1. **Go to the PR** → Files Changed tab
2. **Click the + button** next to any line you want to change
3. **Write your feedback** as a comment (like a prompt to the AI)
4. **Submit the comment** → Pipeline automatically triggers

### Example Comments

| Original Line | Your Comment | AI Revision |
|--------------|--------------|-------------|
| "I was freaking out about the deadline" | "Use more formal tone" | "I was concerned about the deadline" |
| "This is a really good approach" | "Be more specific" | "This approach reduces deployment time by 40%" |
| "The system handles many cases" | "Add concrete examples" | "The system handles user authentication, rate limiting, and error recovery" |
| "Teams should consider this" | "Make it more actionable" | "Engineering leads should implement this pattern in their CI/CD pipeline within the next sprint" |

### Tips for Effective Comments

- **Be specific**: "Use formal tone" works better than "fix this"
- **Give direction**: "Emphasize the cost savings" helps the AI understand intent
- **Reference context**: "This contradicts paragraph 2" helps with consistency
- **Request scope**: "Apply this tone to the whole section" for broader changes

### What Triggers the Revision Pipeline

- Comments on PRs with the `blog-post` label
- Only line-specific comments (not general PR comments)
- The bot will reply to your comment with a summary of changes made

### Iterating on Drafts
```bash
# Edit your draft
vim drafts/my-post.md

# Pipeline re-runs automatically on push
git add drafts/my-post.md
git commit -m "Refine draft with more details"
git push

# New PR will be created/updated
```

## Troubleshooting

### Pipeline Fails at Stage 1
- Check Azure OpenAI credentials
- Verify endpoint and deployment name
- Check GitHub Actions logs for error details

### No Search Results in Stage 2
- Verify BING_SEARCH_KEY is set
- Check if search quota is exceeded
- Pipeline continues without web search if key missing

### Post Quality Issues
- Add more detail to your draft
- Include specific examples and metrics
- Reference sources you want cited
- Use PR comments to request changes

### Action Not Triggering
- Verify file is in `drafts/` directory
- Ensure file ends with `.md`
- Check workflow file path is correct
- Look at Actions tab for errors

## Cost Estimates

### Azure OpenAI
- ~5 API calls per post
- GPT-4: ~$0.15 per post
- GPT-3.5-Turbo: ~$0.03 per post

### Bing Search
- ~5 searches per post
- ~$0.025 per post

### GitHub Actions
- Free tier: 2000 minutes/month
- ~3 minutes per post
- ~660 posts/month free

## Advanced: Local Testing

Test pipeline stages locally:

```bash
# Setup
cd pipeline
pip install -r requirements.txt

# Set environment variables
export AZURE_OPENAI_ENDPOINT="your-endpoint"
export AZURE_OPENAI_KEY="your-key"
export AZURE_OPENAI_DEPLOYMENT="gpt-4"
export BING_SEARCH_KEY="your-bing-key"

# Run individual stages
python stage1_structure.py \
  --input ../drafts/test.md \
  --output temp/stage1.json

python stage2_grounding.py \
  --input temp/stage1.json \
  --output temp/stage2.json

# Continue through all stages...
```

## FAQ

**Q: Can I use a different AI provider?**
A: Yes, modify the scripts to use OpenAI API, Anthropic, etc. The prompt structure stays the same.

**Q: How do I change the blog post format?**
A: Edit the frontmatter template in `stage5_review.py` to match your static site generator (Jekyll, Hugo, etc.)

**Q: Can I run this on other platforms?**
A: Yes - adapt to GitLab CI, Azure DevOps, or any CI/CD system. The Python scripts are platform-agnostic.

**Q: What if I want human review between stages?**
A: Modify the workflow to create intermediate artifacts and pause for approval between stages.

**Q: How do I preserve my draft after processing?**
A: Drafts stay in `drafts/` - they're never deleted. The pipeline only creates new files in `posts/`.

## Contributing

Improvements welcome! Common enhancements:
- Additional research sources
- Better prompt templates
- Support for different blog platforms
- Multi-language support
- Custom style guides

## License

MIT - Use freely, attribution appreciated.

## Support

Questions or issues? 
1. Check GitHub Actions logs
2. Review this README
3. Open an issue with error details
